{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4c95066f",
      "metadata": {},
      "source": [
        "# Demo: RLPF Simulation for Ad Text\n",
        "\n",
        "This notebook demonstrates a small RLPF-style workflow using either real Ad Library data or synthetic fallback.\n",
        "\n",
        "**Data source link (not included in the repo):**\n",
        "- Ad Library API docs: https://developers.facebook.com/docs/marketing-api/reference/ads_archive/\n",
        "\n",
        "If you have real data, save it as `demo/ads_real.csv` and make sure it contains a text field such as `ad_creative_body`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3df74a22",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "ROOT = os.path.abspath('..')\n",
        "if ROOT not in sys.path:\n",
        "    sys.path.insert(0, ROOT)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f5581e4",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from src.synthetic_data import generate_synthetic_ads\n",
        "from src.reward_model import train_reward_model\n",
        "from src.rlpf_sim import simulate_rlpf\n",
        "\n",
        "DATA_PATH = 'ads_real.csv'\n",
        "if os.path.exists(DATA_PATH):\n",
        "    df = pd.read_csv(DATA_PATH)\n",
        "else:\n",
        "    df = pd.DataFrame(generate_synthetic_ads(n=300, seed=42))\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05f842cb",
      "metadata": {},
      "outputs": [],
      "source": [
        "df['text'] = df.get('ad_creative_body', df.get('text', '')).fillna('')\n",
        "df = df[df['text'].str.strip().astype(bool)]\n",
        "\n",
        "df['score'] = df.get('ctr', 0).fillna(0)\n",
        "reward_model = train_reward_model(df['text'], df['score'])\n",
        "results = simulate_rlpf(df['text'].tolist()[:50], reward_model, n_variations=5)\n",
        "results[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "deltas = np.array([r['delta'] for r in results])\n",
        "plt.hist(deltas, bins=20)\n",
        "plt.title('Distribution of Reward Improvements')\n",
        "plt.xlabel('Delta')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
